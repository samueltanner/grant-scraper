{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "import time\n",
    "\n",
    "\n",
    "async def get_related_document_urls(grant_url):\n",
    "    files = []\n",
    "    async with async_playwright() as playwright:\n",
    "        browser = await playwright.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(accept_downloads=True)\n",
    "        page = await context.new_page()\n",
    "\n",
    "        await page.goto(grant_url)\n",
    "        await page.wait_for_selector('body')\n",
    "\n",
    "        related_doc_button = page.locator(\n",
    "            'button', has_text='Related Documents')\n",
    "        await related_doc_button.click()\n",
    "\n",
    "        table_p_tag = page.locator(\n",
    "            'p:has-text(\"Click on the following file link(s) to download the related document(s):\")')\n",
    "        if await table_p_tag.is_visible():\n",
    "            table = table_p_tag.locator('xpath=following-sibling::table')\n",
    "            if await table.is_visible():\n",
    "                print(\"Table found\")\n",
    "\n",
    "                table_a_tags = await table.locator('a').all()\n",
    "\n",
    "                for a_tag in table_a_tags:\n",
    "                    a_tag_text = await a_tag.text_content()\n",
    "                    print(f\"Clicking on: {a_tag_text}\")\n",
    "\n",
    "                    await a_tag.click()\n",
    "                    iframe = page.locator('id=attachmentDownload')\n",
    "                    iframe_src = await iframe.get_attribute('src')\n",
    "                    if iframe_src:\n",
    "                        files.append(\n",
    "                            {\"file_name\": a_tag_text, \"url\": iframe_src})\n",
    "\n",
    "        else:\n",
    "            print(\"No table found\")\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    filtered_files = [file for file in files if file.get(\n",
    "        \"file_name\") != \"\" and file.get(\"url\")]\n",
    "    return filtered_files\n",
    "\n",
    "# Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "\n",
    "async def download_file(url, file_name, path='.'):\n",
    "    print(f\"Downloading {url}, file_name: {file_name}, path: {path}\")\n",
    "\n",
    "    # Create the folder for downloads if it doesn't exist\n",
    "    folder_path = os.path.join(path)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Full file path with the original file name\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Attempt to download the file and handle HTTP errors\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "        print(f\"Downloaded: {file_path}\")\n",
    "\n",
    "        # Check if the file is a zip and extract it\n",
    "        if file_name.endswith('.zip'):\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(folder_path)\n",
    "            print(f\"Extracted: {file_path}\")\n",
    "\n",
    "            # Remove the ZIP file after extraction\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed: {file_path}\")\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(f\"Failed to download {file_name}. HTTPError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_related_documents(files, sub_path='.'):\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        url = file.get(\"url\")\n",
    "        file_name = file.get(\"file_name\")\n",
    "        print(f\"Downloading: {file_name}\")\n",
    "        await download_file(url, file_name, path=f'./{sub_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "async def download_grant_documents_for_ai(grant_url):\n",
    "    start = time.time()\n",
    "\n",
    "    grant_id = grant_url.split(\"/\")[-1]\n",
    "    print(f\"Grant ID: {grant_id}\")\n",
    "    files = await get_related_document_urls(grant_url)\n",
    "    await extract_related_documents(files, sub_path=grant_id)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Time taken: {end - start}\")\n",
    "    return grant_id\n",
    "\n",
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def get_file_paths(directory):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_paths = get_file_paths(\"/path/to/directory\")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "async def create_assistant(api_key, grant_url):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    grant_id = await download_grant_documents_for_ai(grant_url)\n",
    "\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Grant Document Assistant\",\n",
    "        instructions=\"You help users understand grant documents.\",\n",
    "        model=\"gpt-4o\",\n",
    "        tools=[{\"type\": \"file_search\"}],\n",
    "    )\n",
    "\n",
    "    vector_store = client.beta.vector_stores.create(name=\"Grant Documents\")\n",
    "\n",
    "    file_paths = get_file_paths(f\"./{grant_id}\")\n",
    "    print(file_paths)\n",
    "    # Ready the files for upload to OpenAI\n",
    "\n",
    "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "    # # Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "    # # and poll the status of the file batch for completion.\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "\n",
    "    # # You can print the status and the file counts of the batch to see the result of this operation.\n",
    "    print(file_batch.status)\n",
    "    print(file_batch.file_counts)\n",
    "\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources={\"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]}},\n",
    "    )\n",
    "    return client, assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_assistant(client, assistant, query):\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id, assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    messages = list(client.beta.threads.messages.list(\n",
    "        thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "    message_content = messages[0].content[0].text\n",
    "    annotations = message_content.annotations\n",
    "    citations = []\n",
    "    for index, annotation in enumerate(annotations):\n",
    "        message_content.value = message_content.value.replace(\n",
    "            annotation.text, f\"[{index}]\")\n",
    "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "            cited_file = client.files.retrieve(file_citation.file_id)\n",
    "            citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "    print(message_content.value)\n",
    "    print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = None\n",
    "client, assistant = await create_assistant(api_key, grant_url=\"https://grants.gov/search-results-detail/356303\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_assistant(client, assistant,\n",
    "                \"What are the eligibility requirements for this grant?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
